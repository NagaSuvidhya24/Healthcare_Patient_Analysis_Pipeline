Health Patient Care Analytics Pipeline

A scalable healthcare data engineering solution using Databricks to ingest, clean, transform, and analyze patient data to support better decision-making and patient care.

Project Architecture

This project follows the Medallion Architecture:

Layer	Purpose:
Bronze	Raw ingestion of patient data
Silver	Cleaned & validated data with business logic
Gold	Aggregated insights for dashboards

Technology Stack
Component	Technology
Data Platform	Databricks
Orchestration	Databricks Workflows
Storage	AWS S3 + Delta Lake
Processing	PySpark / Spark SQL
Governance	Unity Catalog
Visualization	Databricks Dashboard
ğŸ“‚ Repository Structure
ğŸ“ src
 â”œâ”€â”€ 01_setup_catalog_and_schema
 â”œâ”€â”€ 02_ingest_bronze
 â”œâ”€â”€ 03_transform_silver
 â”œâ”€â”€ 04_aggregate_gold
 â””â”€â”€ dashboard

Databricks Workflow (Job Orchestration)

The ETL pipeline is automated using Databricks Workflows.
âœ” We must manually create a Workflow in Databrick
After importing notebooks, a new Workflow (Job) should be created:
Databricks UI â†’ Workflows â†’ Create Job â†’ Add Tasks in order below

Order	Task Name	Notebook	Purpose
1ï¸.Setup Catalog and Schema	01_setup_catalog_and_schema	Create catalog, schemas & tables
2ï¸.Bronze Layer Ingestion	02_ingest_bronze	Load raw data into Bronze tables
3ï¸.Silver Transformations	03_transform_silver	Cleaning, validations, deduplication
4ï¸.Gold Layer Aggregations	04_aggregate_gold	Build analytics-ready datasets

Each task runs on an all-purpose or job cluster.

Scheduling

âœ” Job scheduled daily at 6:00 AM IST
âœ” Fully automated execution â€” no manual trigger needed

Monitoring & Alerts
Feature	Description
Failure Alerts	Email notifications on task failures
Error Logging	Failures stored in health_catalog.logs.etl_errors Delta table
Observability	Job run history stored within Databricks

Dataset Information
Source: Kaggle Heart Disease Dataset
Example fields include:
Patient demographics (age, sex)
Vitals (blood pressure, cholesterol)
Clinical indicators (thalassemia, chest pain type)


Dashboard Insights
Gold layer dataset drives dashboards to analyze:
High-risk patient identification

Age-wise disease distribution

Vital metrics comparisons

Heart disease trends

âœ¨ Key Features

Fully automated data pipeline

Delta Lake ACID capabilities + Time Travel

Data quality validation and error tracking

Scalable Spark-based processing

Secure governance using Unity Catalog

â–¶ï¸ How to Run

1ï¸. Import notebooks into Databricks
2ï¸. Create external location connected to AWS S3
3ï¸. Create Workflow â†’ Add all tasks â†’ Set schedule
4ï¸. Validate output in Bronze â†’ Silver â†’ Gold tables
5ï¸. View dashboards for final analytics

Future Enhancements

Streaming ingestion using Auto Loader

ML-based patient risk prediction

CI/CD automation using Databricks Repos

Data lineage visualization

